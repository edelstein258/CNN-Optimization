<!DOCTYPE html>
<html><head>
  <meta http-equiv="Content-Security-Policy" content="default-src chrome:; img-src *; media-src *">
  <meta content="text/html; charset=UTF-8" http-equiv="content-type">
  <meta name="viewport" content="width=device-width; user-scalable=0">
  <link rel="stylesheet" href="Knowledge%20Distillation%20%E2%80%93%20Neural%20Machines%20%E2%80%93%20Medium_files/aboutReader.css" type="text/css">
  <script type="text/javascript" src="Knowledge%20Distillation%20%E2%80%93%20Neural%20Machines%20%E2%80%93%20Medium_files/aboutReader.js"></script>
<link rel="stylesheet" href="Knowledge%20Distillation%20%E2%80%93%20Neural%20Machines%20%E2%80%93%20Medium_files/narrate.css"><title>Knowledge Distillation ‚Äì Neural Machines ‚Äì Medium</title><link rel="shortcut icon" href="https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico"></head>

<body class="light sans-serif loaded">
  <div class="container font-size5 content-width3">
    <div class="header reader-header" style="display: block;">
      <a class="domain reader-domain" href="https://medium.com/neural-machines/knowledge-distillation-dc241d7c2322">medium.com</a>
      <div class="domain-border"></div>
      <h1 class="reader-title">Knowledge Distillation ‚Äì Neural Machines ‚Äì Medium</h1>
      <div class="credits reader-credits">Ujjwal Upadhyay</div>
      <div class="meta-data">
        <div class="reader-estimated-time">10-13 minutes</div>
      </div>
    </div>

    <hr>

    <div class="content">
      <div class="moz-reader-content line-height4" style="display: block;"><div id="readability-page-1" class="page"><section name="62b2"><div><div><figure name="ecb0" id="ecb0"><div></div></figure><p name="8a35" id="8a35">The
 problem that we are facing right now is that we have built 
sophisticated models that can perform complex tasks, but the question 
is, how do we deploy such bulky models on our mobile devices for instant
 usage. Obviously we can deploy our model to the cloud and can call it 
whenever we need its service but this would require reliable internet 
connection and hence it becomes a constraint in production. So what we 
need is a model that can run on our mobile devices.</p><figure name="96d9" id="96d9"><div></div></figure><p name="fa39" id="fa39"><strong>So what‚Äôs the problem&nbsp;? </strong>We
 can train a small network that can run on limited computational 
resource of our mobile device. But there is a problem in this approach. 
Small models can‚Äôt extract much complex features that can be handy in 
generating predictions unless you devise some elegant algorithm to do 
so. Though ensemble of small models gives good results, but 
unfortunately making predictions using a whole ensemble of models is 
cumbersome and may be too computationally expensive to allow deployment 
to a large number of users. In this case, we resort to either of the 2 
techniques:</p><ul><li name="e75d" id="e75d">Knowledge Distillation</li><li name="25cc" id="25cc">Model Compression</li><li name="c235" id="c235">If you have developed a better solution or if I might have missed something, please mention in the comments üôÇ</li></ul><p name="f7e0" id="f7e0">In this blog, we will look at <strong>Knowledge Distillation. </strong>I will cover model compression in an upcoming blog.</p><p name="6791" id="6791">So
 knowledge distillation is a simple way to improve the performance of 
deep learning models on mobile devices. In this process, we train a 
large and complex network or a ensemble model which can extract 
important features from the given data and can therefore produce better 
predictions. Then we train a small network with the help of the 
cumbersome model. This small network will be able to produce comparable 
results, and in some cases, it can even be made capable of replicating 
the results of the cumbersome network.</p><figure name="9137" id="9137"><div></div></figure><p name="8be8" id="8be8">For
 example, Since GoogLeNet is a very cumbersome (means deep and complex) 
network, its deepness gives ability to extract and complex features and 
its complexity gives it power to remain accurate. But the model is heavy
 enough that one for sure need large amount of memory and a powerful GPU
 to perform large and complex calculations. So that‚Äôs why we need to 
transfer the knowledge learnt by this model to a much smaller model 
which can easily be used in mobile.</p><h4 name="ef36" id="ef36">About Cumbersome Models</h4><p name="5465" id="5465">Cumbersome models learns to discriminate between a large number of classes. The normal <strong>training objective</strong>
 is to maximize the average log probability of the correct answer, and 
it assigns probability to all the classes, with some classes given small
 probabilities with respect to others. The relative probabilities of 
incorrect answers tell us a lot about how this complex model tends to 
generalize. An image of a Car, for example, may only have a very small 
chance of being mistaken for a Truck, but that mistake is still many 
times more probable than mistaking it for a Cat.</p><blockquote name="8607" id="8607">Note
 that objective function should be chosen such that it generalizes well 
to new data. So it should be kept in mind while selecting an appropriate
 objective function that it shouldn‚Äôt be selected in such a way that it 
optimizes well on training data.</blockquote><p name="9ff5" id="9ff5">Since
 these operation will be quite heavy for a mobile during performance, so
 to deal with this situation, we have to transfer the knowledge of the 
cumbersome model to a small model which can be easily exported to mobile
 devices. To achieve this, we can consider the cumbersome model as <strong>Teacher Network</strong> and our new small model as <strong>Student Network.</strong></p><h4 name="e4df" id="e4df">Teacher and&nbsp;Student</h4><p name="e3bc" id="e3bc">You
 can ‚Äòdistill‚Äô the large and complex network in another much smaller 
network, and the smaller network does a reasonable job of approximating 
the original function learnt by a deep network.</p><figure name="26c9" id="26c9"><div></div></figure><p name="74fa" id="74fa">However, there is a catch, the distilled model (<strong>student</strong>), is trained to mimic the output of the larger network (<strong>teacher</strong>),
 instead of training it on the raw data directly. This has something to 
do with how the deeper network learns hierarchical abstractions of the 
features.</p><h4 name="0e4c" id="0e4c">So how is this transfer of knowledge done?</h4><p name="7c58" id="7c58">The
 transferring of the generalization ability of the cumbersome model to a
 small model can be done by the use of class probabilities produced by 
the cumbersome model as ‚Äúsoft targets‚Äù for training the small model. For
 this transfer stage, we use the same training set or a separate 
‚Äútransfer‚Äù set as used for training cumbersome model. When the 
cumbersome model is a large ensemble of simpler models, we can use an 
arithmetic or geometric mean of their individual predictive 
distributions as the soft targets. <span name="anon_44b6da084425" data-creator-ids="anon">When
 the soft targets have high entropy, they provide much more information 
per training case than hard targets and much less variance in the 
gradient between training cases, so the small model can often be trained
 on much less data than the original cumbersome model while using a much
 higher learning rate.</span></p><figure name="88a2" id="88a2"><div></div></figure><p name="6bc0" id="6bc0">Much
 of the information about the learned function resides in the ratios of 
very small probabilities in the soft targets. This is valuable 
information that defines a rich similarity structure over the data (i. 
e. it says which 2‚Äôs look like 3‚Äôs and which look like 7‚Äôs or which 
‚Äúgolden retriever‚Äù looks like ‚Äúlabrador‚Äù) but it has very little 
influence on the cross-entropy cost function during the transfer stage 
because the probabilities are so close to zero.</p><h4 name="7352" id="7352">Distillation</h4><p name="40f4" id="40f4">For distilling the learned knowledge we use <strong>Logits</strong>
 (the inputs to the final softmax). Logits can be used for learning the 
small model and this can be done by minimizing the squared difference 
between the logits produced by the cumbersome model and the logits 
produced by the small model.</p><figure name="acb7" id="acb7"><div><img data-image-id="1*yJD5529FbmtbZ-GC25_ITw.png" data-width="364" data-height="76" src="Knowledge%20Distillation%20%E2%80%93%20Neural%20Machines%20%E2%80%93%20Medium_files/1yJD5529FbmtbZ-GC25_ITw.png"></div><figcaption>Softmax with Temperature</figcaption></figure><p name="dc5f" id="dc5f">For high temperatures (<strong><em>T -&gt; inf</em></strong>), all actions have nearly the same probability and at the lower the temperature (<strong><em>T -&gt; 0</em></strong>),
 the more expected rewards affect the probability. For a low 
temperature&nbsp;, the probability of the action with the highest 
expected reward tends to 1.</p><p name="7fcf" id="7fcf">In distillation,
 we raise the temperature of the final softmax until the cumbersome 
model produces a suitably soft set of targets. We then use the same high
 temperature when training the small model to match these soft targets.</p><h4 name="37eb" id="37eb">Objective Function</h4><p name="e79b" id="e79b">The
 first objective function is the cross entropy with the soft targets and
 this cross entropy is computed using the same high temperature in the 
softmax of the distilled model as was used for generating the soft 
targets from the cumbersome model.</p><p name="dab1" id="dab1">The 
second objective function is the cross entropy with the correct labels 
and this is computed using exactly the same logits in softmax of the 
distilled model but at a temperature of 1</p><figure name="f5e7" id="f5e7"><div></div></figure><h4 name="6f21" id="6f21">Training ensembles of specialists</h4><p name="9139" id="9139">Training
 an ensemble of models is a very simple way to take advantage of 
parallel computation. But there is an objection that an ensemble 
requires too much computation at test time. But this can be easily dealt
 with the technique we are learning. And so ‚ÄúDistillation‚Äù can be used 
to deal with this allegation.</p><figure name="b250" id="b250"><div></div></figure><h4 name="4ede" id="4ede"><strong>Specialist Models</strong></h4><p name="080b" id="080b"><em>Specialist models and one generalist model make our one cumbersome model</em>.
 Generalist Model is trained on all training data and Specialist Models 
focus on a different confusable subset of the classes can reduce the 
total amount of computation required to learn an ensemble. The main 
problem with specialists is that they overfit very easily. But this 
overfitting may be prevented by using soft targets.</p><h4 name="41a1" id="41a1">Reduce Overfitting in Specialist Models</h4><p name="162b" id="162b">To
 reduce overfitting and share the work of learning lower level feature 
detectors, each specialist model is initialized with the weights of the 
generalist model. These weights are then slightly modified by training 
the specialist, with half its examples coming from its special subset, 
and half sampled at random from the remainder of the training set. After
 training, we can correct for the biased training set by incrementing 
the logit of the dustbin class by the log of the proportion by which the
 specialist class is oversampled.</p><figure name="4cf0" id="4cf0"><div></div></figure><h4 name="077a" id="077a">Assign classes to Specialists</h4><p name="ee7b" id="ee7b">We
 apply a clustering algorithm to the covariance matrix of the 
predictions of our generalist model, so that a set of classes Sm that 
are often predicted together will be used as targets for one of our 
specialist models, m. So we apply K-means clustering to the columns of 
covariance matrix to get our required clusters or classes.</p><figure name="3812" id="3812"><div></div><figcaption><code><strong>Assign a score to an ordered covariance matrix. High correlations within a cluster improve the score.<br>&nbsp;High correlations between clusters decease the&nbsp;score.</strong></code></figcaption></figure><blockquote name="3d6e" id="3d6e">Covariance/Correlation
 clustering provides a method for clustering a set of objects into the 
optimum number of clusters without specifying that number 
in&nbsp;advance.</blockquote><h4 name="776e" id="776e">Performing inference</h4><ul><li name="3887" id="3887">For each test case, we find the ‚Äòn‚Äô most probable classes according to the generalist model. Call this set of classes k.</li><li name="03a4" id="03a4">We
 then take all the specialist models, m, whose special subset of 
confusable classes, Sm, has a non-empty intersection with k and call 
this the active set of specialists Ak (note that this set may be empty).
 We then find the full probability distribution q over all the classes 
that minimizes:</li></ul><figure name="4415" id="4415"><div><img data-image-id="1*NRXkBNMx4VE5xDYGl5aB-w.png" data-width="398" data-height="88" src="Knowledge%20Distillation%20%E2%80%93%20Neural%20Machines%20%E2%80%93%20Medium_files/1NRXkBNMx4VE5xDYGl5aB-w.png"></div></figure><figure name="38e9" id="38e9"><div><img data-image-id="1*MpnL9tKLfqAdhAJkY6hnwA.png" data-width="267" data-height="68" src="Knowledge%20Distillation%20%E2%80%93%20Neural%20Machines%20%E2%80%93%20Medium_files/1MpnL9tKLfqAdhAJkY6hnwA.png"></div></figure><p name="b254" id="b254">KL
 denotes the KL divergence, and p^m, p^g denote the probability 
distribution of a specialist model or the generalist full model. The 
distribution p^m is over all the specialist classes of m plus a single 
dustbin class, so when computing its KL divergence from the full q 
distribution we sum all of the probabilities that the full q 
distribution assigns to all the classes in m‚Äôs dustbin.</p><h4 name="bafc" id="bafc">Soft Targets as Regularizers</h4><p name="09f1" id="09f1">Soft
 Targets, or labels predicted from a model contain more information that
 binary hard labels due to the fact that they encode similarity measures
 between the classes.</p><p name="2109" id="2109">Incorrect labels 
tagged by the model describe co-label similarities, and these 
similarities should be evident in future stages of learning, even if the
 effect is diminished. For example, imagine training a deep neural net 
on a classification dataset of various dog breeds. In the initial few 
stages of learning the model will not accurately distinguish between 
similar dog-breeds such as a Belgian Shepherd versus a German Shepherd. 
This same effect, although not so exaggerated, should appear in later 
stages of training. If, given an image of a German Shepherd, the model 
predicts the class German Shepherd with a high-accuracy, the next 
highest predicted dog should still be a Belgian Shepherd, or a similar 
looking dog. Over-fitting starts to occur when the majority of these 
co-label effects begin to disappear. By forcing the model to contain 
these effects in the later stages of training, we reduced the amount of 
over-fitting.</p><blockquote name="a456" id="a456"><strong>Though using soft targets as Regularizers is not considered very effective.</strong></blockquote></div></div></section><section name="1f59"></section></div></div>
    </div>

    <div>
      <div class="reader-message" style="display: none;"></div>
    </div>
  </div>

  <ul class="toolbar reader-toolbar">
    <li><button class="button close-button" title="Close Reader View"></button></li>
    <ul class="dropdown style-dropdown">
      <li><button class="dropdown-toggle button style-button" title="Type controls"></button></li>
      <li class="dropdown-popup">
        <div class="font-type-buttons"><button class="sans-serif-button selected"><div class="name">Aa</div><div class="description">Sans-serif</div></button><button class="serif-button"><div class="name">Aa</div><div class="description">Serif</div></button></div>
        <hr>
        <div class="font-size-buttons">
          <button class="minus-button">
          </button><button class="font-size-sample">Aa</button><button class="plus-button">
        </button></div>
        <hr>
        <div class="content-width-buttons">
          <button class="content-width-minus-button">
          </button><button class="content-width-plus-button">
        </button></div>
        <hr>
        <div class="line-height-buttons">
          <button class="line-height-minus-button">
          </button><button class="line-height-plus-button">
        </button></div>
        <hr>
        <div class="color-scheme-buttons"><button class="light-button selected"><div class="name">Light</div></button><button class="dark-button"><div class="name">Dark</div></button><button class="sepia-button"><div class="name">Sepia</div></button></div>
        <div class="dropdown-arrow">
      </div></li>
    </ul>
  <ul class="dropdown narrate-dropdown"><li>
       <button class="dropdown-toggle button narrate-toggle" title="Narrate"></button>
    </li>
    <li class="dropdown-popup">
      <div class="narrate-row narrate-control">
        <button disabled="disabled" class="narrate-skip-previous" title="Back"></button>
        <button class="narrate-start-stop" title="Start"></button>
        <button disabled="disabled" class="narrate-skip-next" title="Forward"></button>
      </div>
      <div class="narrate-row narrate-rate">
        <input class="narrate-rate-input" value="0" step="5" max="100" min="-100" title="Speed" type="range">
      </div>
      <div class="narrate-row narrate-voices"><div class="voiceselect voice-select"><button class="select-toggle" aria-controls="voice-options">
      <span class="label">Voice:</span> <span class="current-voice">Default</span>
    </button>
    <div class="options" id="voice-options" role="listbox"><button data-value="automatic" class="option selected" tabindex="-1" role="option" aria-selected="true">Default</button><button data-value="urn:moz-tts:speechd:english_rp?en-GB" class="option" tabindex="-1" role="option">English (en-GB)</button><button data-value="urn:moz-tts:speechd:english?en-GB" class="option" tabindex="-1" role="option">English (en-GB)</button><button data-value="urn:moz-tts:speechd:english_wmids?en-GB" class="option" tabindex="-1" role="option">English (en-GB)</button><button data-value="urn:moz-tts:speechd:english-north?en-GB" class="option" tabindex="-1" role="option">English (en-GB)</button><button data-value="urn:moz-tts:speechd:en-scottish?en-SC" class="option" tabindex="-1" role="option">English (en-SC)</button><button data-value="urn:moz-tts:speechd:english-us?en-US" class="option" tabindex="-1" role="option">English (en-US)</button><button data-value="urn:moz-tts:speechd:en-westindies?en-WI" class="option" tabindex="-1" role="option">English (en-WI)</button><button data-value="urn:moz-tts:speechd:default?en" class="option" tabindex="-1" role="option">English (en)</button></div></div></div>
      <div class="dropdown-arrow"></div>
    </li></ul><button data-buttonid="pocket-button" class="button pocket-button" style="background-image: url(&quot;chrome://pocket/content/panels/img/pocket.svg#pocket-mark&quot;);" title="Save to Pocket"></button></ul>




</body></html>